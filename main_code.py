# ===================== IMPORTS ===================== #
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from wordcloud import WordCloud
from pyvi.ViTokenizer import tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import pickle
import streamlit as st
from sklearn.preprocessing import PowerTransformer
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from category_encoders import CatBoostEncoder
from PIL import Image
import io

# ==============================================
#  ƒê∆Ø·ªúNG D·∫™N FILE D·ªÆ LI·ªÜU CHUNG CHO ADMIN + USER
# ==============================================
DATA_PATH = "uploaded_data.xlsx"

# ==============================================
#  KH·ªûI T·∫†O TR·∫†NG TH√ÅI CHUNG
# ==============================================
if "app_mode" not in st.session_state:
    st.session_state.app_mode = None        # "user" ho·∫∑c "admin"
if "file_ready" not in st.session_state:
    st.session_state.file_ready = False     # ƒê√£ c√≥ file d·ªØ li·ªáu chung ch∆∞a

# ===================== CUSTOM CSS ===================== #
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap');

    html, body, [class*="css"] {
        font-family: 'Poppins', sans-serif;
    }

    /* Title Style */
    .title-center {
        text-align: center;
        font-size: 40px !important;
        font-weight: 600 !important;
        color: #2C3E50;
        padding-bottom: 10px;
    }

    /* Header Gradient */
    .header {
        background: linear-gradient(90deg, #0062E6, #33AEFF);
        padding: 15px;
        border-radius: 10px;
        color: white;
        margin-bottom: 20px;
        text-align: center;
        font-size: 22px;
        font-weight: 600;
    }

    /* Card Style */
    .card {
        background-color: #ffffff;
        padding: 20px;
        border-radius: 12px;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1);
        text-align: center;
        margin-bottom: 20px;
    }

    .card h3 {
        margin: 0;
        color: #2C3E50;
        font-weight: 600;
    }

    .card p {
        margin: 0;
        font-size: 24px;
        color: #2980B9;
        font-weight: 600;
    }

    /* Center Image */
    .center-img {
        display: flex;
        justify-content: center;
        margin-bottom: 20px;
    }
    
    /* FULL PAGE WIDTH */
    .block-container {
        max-width: 77% !important;
        padding-left: 2rem !important;
        padding-right: 2rem !important;
    }

    /* FIX COLUMN WIDTH */
    .css-1r6slb0, .css-12oz5g7 {
        flex: 1 !important;
    }
    </style>
""", unsafe_allow_html=True)

# ================= S·∫¢NH CH·ªú CH·ªåN CH·∫æ ƒê·ªò ================= #
def show_lobby():
    """S·∫£nh ch·ªù: bu·ªôc ch·ªçn ch·∫ø ƒë·ªô tr∆∞·ªõc khi v√†o app ch√≠nh"""
    st.title("üö™ Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi h·ªá th·ªëng ph√¢n t√≠ch xe m√°y")
    st.write("Vui l√≤ng ch·ªçn **ch·∫ø ƒë·ªô s·ª≠ d·ª•ng** ƒë·ªÉ ti·∫øp t·ª•c:")

    col1, col2 = st.columns(2)
    with col1:
        if st.button("üë§ Ng∆∞·ªùi d√πng", use_container_width=True):
            # Ng∆∞·ªùi d√πng v√†o tr∆∞·ªõc khi c√≥ d·ªØ li·ªáu -> ch·ªâ xem ƒë∆∞·ª£c 3 trang
            st.session_state.app_mode = "user"
            st.rerun()
    with col2:
        if st.button("üõ† Qu·∫£n tr·ªã", use_container_width=True):
            st.session_state.app_mode = "admin"
            st.rerun()

    st.stop()

# N·∫øu ch∆∞a ch·ªçn mode ‚Üí s·∫£nh ch·ªù
if st.session_state.app_mode is None:
    show_lobby()

# ============================================
#  BACKEND H√ÄM DUY NH·∫§T (LOAD + TI·ªÄN X·ª¨ L√ù)
# ============================================
@st.cache_resource
@st.cache_resource
def load_backend(file_content):

    df = pd.read_excel(io.BytesIO(file_content))

    # ==== Load stopwords ====
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    STOP_WORD_FILE = os.path.join(BASE_DIR, "vietnamese-stopwords.txt")
    with open(STOP_WORD_FILE, "r", encoding="utf-8") as f:
        stop_words = f.read().split("\n")

    # ==== Load dictionaries ====
    def load_dict(path):
        d = {}
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                parts = line.strip().split("\t")
                if len(parts) == 2:
                    d[parts[0]] = parts[1]
        return d

    emoji_dict = load_dict(os.path.join(BASE_DIR, "emojicon.txt"))
    wrong_dict = load_dict(os.path.join(BASE_DIR, "wrong-word.txt"))

    df["id"] = range(len(df))

    # ==== Text utils ====
    def normalize_text_light(text):
        text = str(text).lower()
        for k, v in emoji_dict.items():
            text = text.replace(k, f" {v} ")
        for k, v in wrong_dict.items():
            text = text.replace(k, f" {v} ")
        text = re.sub(r"[^\w\s]", " ", text)
        return re.sub(r"\s+", " ", text).strip()

    def remove_stopwords(text):
        return " ".join([w for w in text.split() if w not in stop_words])

    def preprocess_text(text):
        return " ".join(tokenize(remove_stopwords(normalize_text_light(text))))

    # ==== TF-IDF ====
    if "Content_wt_joined" not in df.columns:
        df["Content_wt"] = df["Content"].apply(normalize_text_light).apply(remove_stopwords)
        df["Content_wt_joined"] = df["Content_wt"].apply(lambda x: " ".join(tokenize(x)))

    df.loc[df["Content_wt_joined"].str.strip() == "", "Content_wt_joined"] = df["Ti√™u ƒë·ªÅ"]

    vectorizer = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b", min_df=2)
    tfidf_matrix = vectorizer.fit_transform(df["Content_wt_joined"])

    # ==== Load cosine_matrix ====
    with open(os.path.join(BASE_DIR, "Cosine_similarity_matrix.pkl"), "rb") as f:
        cosine_sim = pickle.load(f)

    return df, cosine_sim, vectorizer, tfidf_matrix, normalize_text_light, remove_stopwords, preprocess_text

# ===================== SIDEBAR & CHUY·ªÇN MODE ===================== #

st.sidebar.title("‚öô Menu")

# Th√¥ng b√°o ch·∫ø ƒë·ªô hi·ªán t·∫°i
if st.session_state.app_mode == "user":
    st.sidebar.markdown("**Ch·∫ø ƒë·ªô hi·ªán t·∫°i:** üë§ Ng∆∞·ªùi d√πng")
else:
    st.sidebar.markdown("**Ch·∫ø ƒë·ªô hi·ªán t·∫°i:** üõ† Qu·∫£n tr·ªã")

uploaded_file = None

# ---- ADMIN: c√≥ quy·ªÅn upload file ----
if st.session_state.app_mode == "admin":
    uploaded_file = st.sidebar.file_uploader("üì§ T·∫£i l√™n file Excel", type=["xlsx", "xls"])
    if uploaded_file is not None:

        # Ghi d·ªØ li·ªáu file v√†o RAM
        st.session_state["excel_bytes"] = uploaded_file.getvalue()
        st.session_state.file_ready = True

        st.success("‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu v√†o RAM!")

        # Kh√¥ng rerun ·ªü ƒë√¢y, rerun s·∫Ω l√†m sidebar m·∫•t widget
        # st.rerun()

# ---- Widget chuy·ªÉn mode (ch·ªâ xu·∫•t hi·ªán khi ƒë√£ c√≥ d·ªØ li·ªáu) ----
if st.session_state.file_ready:
    with st.sidebar.expander("üîÅ Chuy·ªÉn ƒë·ªïi ch·∫ø ƒë·ªô"):
        if st.session_state.app_mode == "admin":
            if st.button("üë§ Chuy·ªÉn sang Ng∆∞·ªùi d√πng", use_container_width=True):
                st.session_state.app_mode = "user"
                st.rerun()
        else:
            if st.button("üõ† Chuy·ªÉn sang Qu·∫£n tr·ªã", use_container_width=True):
                st.session_state.app_mode = "admin"
                st.rerun()

# ===================== X√ÇY D·ª∞NG MENU ===================== #

# Ng∆∞·ªùi d√πng:
#   - n·∫øu ch∆∞a c√≥ d·ªØ li·ªáu -> 3 trang
#   - n·∫øu ƒë√£ c√≥ d·ªØ li·ªáu do admin upload -> full ch·ª©c nƒÉng (nh∆∞ng kh√¥ng ƒë∆∞·ª£c upload)
if st.session_state.app_mode == "user":
    if st.session_state.file_ready:
        menu = [
            "Trang ch·ªß",
            "M√¥ t·∫£ ·ª©ng d·ª•ng",
            "B·∫£ng ƒëi·ªÅu h∆∞·ªõng",
            "ƒê·ªÅ xu·∫•t & Ph√¢n c·ª•m",
            "Tr·ª±c quan h√≥a",
            "Ph·ª• tr√°ch ·ª©ng d·ª•ng"
        ]
    else:
        menu = ["Trang ch·ªß", "M√¥ t·∫£ ·ª©ng d·ª•ng", "Ph·ª• tr√°ch ·ª©ng d·ª•ng"]

# Admin:
#   - tr∆∞·ªõc khi upload -> 3 trang
#   - sau khi upload -> full ch·ª©c nƒÉng
else:
    if st.session_state.file_ready:
        menu = [
            "Trang ch·ªß",
            "M√¥ t·∫£ ·ª©ng d·ª•ng",
            "B·∫£ng ƒëi·ªÅu h∆∞·ªõng",
            "ƒê·ªÅ xu·∫•t & Ph√¢n c·ª•m",
            "Tr·ª±c quan h√≥a",
            "Ph·ª• tr√°ch ·ª©ng d·ª•ng"
        ]
    else:
        menu = ["Trang ch·ªß", "M√¥ t·∫£ ·ª©ng d·ª•ng", "Ph·ª• tr√°ch ·ª©ng d·ª•ng"]

page = st.sidebar.radio("Go to:", menu)

# ===================== LOAD DATA CHUNG (ADMIN + USER) ===================== #
df = None
cosine_sim = vectorizer = tfidf_matrix = None
normalize_text_light = remove_stopwords = preprocess_text = None

df = None
if st.session_state.file_ready and "excel_bytes" in st.session_state:
    df, cosine_sim, vectorizer, tfidf_matrix, normalize_text_light, remove_stopwords, preprocess_text = \
        load_backend(st.session_state["excel_bytes"])


# ===== Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh cho card th·ªëng k√™ =====
if "total_items" not in st.session_state:
    st.session_state["total_items"] = len(df) if df is not None else 0
if "total_clusters" not in st.session_state:
    st.session_state["total_clusters"] = 0

def require_file_loaded():
    """D√πng cho c·∫£ Admin + User: bu·ªôc ph·∫£i c√≥ d·ªØ li·ªáu tr∆∞·ªõc khi d√πng module."""
    if df is None:
        st.warning("‚ö† Vui l√≤ng ƒë·ªÉ Admin upload file Excel tr∆∞·ªõc khi s·ª≠ d·ª•ng ch·ª©c nƒÉng n√†y.")
        st.stop()

#############################################################
# =========== RECOMMEND FUNCTIONS =========== #

def get_recomendations(id, cosine_sim=cosine_sim, nums=7):
    idx = df.index[df["id"] == id][0]
    scores = list(enumerate(cosine_sim[idx]))
    scores = sorted(scores, key=lambda x: x[1], reverse=True)[1:nums+1]

    indices = [i[0] for i in scores]
    res = df.iloc[indices][["id", "Ti√™u ƒë·ªÅ", "Th∆∞∆°ng hi·ªáu", "Gi√°", "S·ªë Km ƒë√£ ƒëi", "ƒê·ªãa ch·ªâ"]].copy()
    res["Cosine_Similarity"] = [round(i[1], 3) for i in scores]
    return res

def recommend_by_keyword(keyword, nums=7):
    keyword_clean = preprocess_text(keyword)
    if keyword_clean.strip() == "":
        return df.head(nums)

    keyword_vec = vectorizer.transform([keyword_clean])
    scores = cosine_similarity(keyword_vec, tfidf_matrix).flatten()

    if scores.max() == 0:
        return df.head(nums)

    top_idx = scores.argsort()[::-1][:nums]
    res = df.iloc[top_idx][["id", "Ti√™u ƒë·ªÅ", "Th∆∞∆°ng hi·ªáu", "Gi√°", "Dung t√≠ch xe", "S·ªë Km ƒë√£ ƒëi", "ƒê·ªãa ch·ªâ"]]
    res["Cosine_Similarity"] = scores[top_idx]
    return res

#############################################################
# ===================== HEADER & CARDS ===================== #
st.markdown("<div class='header'>B·∫£ng ƒëi·ªÅu khi·ªÉn d·ª± ƒëo√°n & ph√¢n c·ª•m xe m√°y</div>",
            unsafe_allow_html=True)

st.markdown("<h1 class='title-center'>·ª®ng d·ª•ng d·ª± ƒëo√°n v√† ph√¢n c·ª•m xe m√°y</h1>",
            unsafe_allow_html=True)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
image_path = os.path.join(BASE_DIR, "Logo_ChoTot.png")
st.image(image_path, use_container_width=True)

col1, col2 = st.columns([1, 1])
total_items = st.session_state.get("total_items", len(df) if df is not None else 0)
cluster_count = st.session_state.get("total_clusters", 0)

with col1:
    st.markdown(f"""
        <div class='card'>
            <h3>T·ªïng s·∫£n ph·∫©m ƒë√£ x·ª≠ l√Ω</h3>
            <p>{total_items}</p>
        </div>
    """, unsafe_allow_html=True)

with col2:
    st.markdown(f"""
        <div class='card'>
            <h3>S·ªë c·ª•m ƒë√£ x√°c ƒë·ªãnh</h3>
            <p>{cluster_count}</p>
        </div>
    """, unsafe_allow_html=True)

#############################################################
# ======================= ROUTING ========================= #

# =============== PAGE: Trang ch·ªß =============== #
if page == "Trang ch·ªß":
    st.subheader("üèçÔ∏è Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng ph√¢n t√≠ch xe m√°y c·ªßa ch√∫ng t√¥i!")
    st.write("""
        ƒê·∫∑t v·∫•n ƒë·ªÅ: M·ªôt s√†n th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ (ho·∫∑c website rao v·∫∑t xe m√°y c≈© nh∆∞ Ch·ª£ T·ªët,...) ƒëang g·∫∑p 3 v·∫•n ƒë·ªÅ l·ªõn:
        - Ng∆∞·ªùi mua kh√≥ t√¨m ƒë√∫ng xe ph√π h·ª£p v√¨ s·ªë tin ƒëƒÉng l·ªõn nh∆∞ng h·ªá th·ªëng tr·∫£ k·∫øt qu·∫£ kh√¥ng th·ª±c s·ª± gi·ªëng v·ªõi nhu c·∫ßu.
        - Ng∆∞·ªùi mua kh√¥ng bi·∫øt m·ª©c gi√° n√†o l√† h·ª£p l√Ω c√≥ th·ªÉ c√πng m·ªôt m·∫´u xe nh∆∞ng gi√° dao ƒë·ªông r·∫•t m·∫°nh
        - Ng∆∞·ªùi b√°n kh√¥ng bi·∫øt nh√≥m kh√°ch h√†ng n√†o ph√π h·ª£p v·ªõi xe c·ªßa h·ªç ƒë·ªÉ t·ªëi ∆∞u ho√° vi·ªác ti·∫øp c·∫≠n kh√°ch h√†ng ti·ªÅm nƒÉng.
             
        ·ª®ng d·ª•ng n√†y cho ph√©p b·∫°n:
        - üîç T√¨m ki·∫øm xe t∆∞∆°ng t·ª± b·∫±ng H·ªá th·ªëng ƒë·ªÅ xu·∫•t  
        - üìä Th·ª±c hi·ªán ph√¢n c·ª•m d·ª±a v√†o nhi·ªÅu thu·ªôc t√≠nh  
        - üé® Tr·ª±c quan h√≥a d·ªØ li·ªáu d·ªÖ d√†ng  
    """)
    st.info("Ch·ªçn m·ª•c ·ªü thanh b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

# =============== PAGE: M√¥ t·∫£ ·ª©ng d·ª•ng =============== #
elif page == "M√¥ t·∫£ ·ª©ng d·ª•ng":
    st.subheader("üìò Gi·ªõi thi·ªáu ·ª®ng d·ª•ng")
    st.write("""
        ·ª®ng d·ª•ng ƒë∆∞·ª£c x√¢y d·ª±ng g·ªìm 2 module ch√≠nh:

        **1Ô∏è‚É£ H·ªá th·ªëng ƒë·ªÅ xu·∫•t**
        - T√¨m nh·ªØng xe m√°y gi·ªëng nh·∫•t d·ª±a v√†o ID, T·ª´ kh√≥a,‚Ä¶  
        - S·ª≠ d·ª•ng TF-IDF + Cosine Similarity  
        - Cho ph√©p g·ª£i √Ω theo **ID** ho·∫∑c theo **Keyword**

        **2Ô∏è‚É£ Ph√¢n c·ª•m**
        - Gom nh√≥m xe theo gi√°, h√£ng, dung t√≠ch, nƒÉm ƒëƒÉng k√Ω‚Ä¶  
        - Thu·∫≠t to√°n h·ªó tr·ª£:
            - KMeans
            - Agglomerative
            - Gaussian Mixture Model
        - Gi·∫£m chi·ªÅu: PCA, t-SNE, UMAP

        **3Ô∏è‚É£ Tr·ª±c quan h√≥a**
        - Wordcloud
        - Bi·ªÉu ƒë·ªì ph√¢n b·ªë gi√°
        - Countplot th∆∞∆°ng hi·ªáu  
    """)

# =============== PAGE: B·∫£ng ƒëi·ªÅu h∆∞·ªõng =============== #
elif page == "B·∫£ng ƒëi·ªÅu h∆∞·ªõng":
    require_file_loaded()

    st.subheader("üõ† Control Panel Settings")
    st.write("C·∫•u h√¨nh chung cho app (tu·ª≥ ch·ªçn m·ªü r·ªông):")

    items = st.slider("S·ªë l∆∞·ª£ng items hi·ªÉn th·ªã", 5, 50, 10)
    show_price = st.checkbox("Hi·ªÉn th·ªã th√¥ng tin gi√°", True)
    show_brand = st.checkbox("Hi·ªÉn th·ªã th∆∞∆°ng hi·ªáu", True)

    st.success("C√†i ƒë·∫∑t ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng.")

# =============== PAGE: ƒê·ªÅ xu·∫•t & Ph√¢n c·ª•m =============== #
elif page == "ƒê·ªÅ xu·∫•t & Ph√¢n c·ª•m":
    require_file_loaded()

    tab1, tab2 = st.tabs(["üîç H·ªá th·ªëng ƒë·ªÅ xu·∫•t", "üì¶ Ph√¢n c·ª•m"])

    # TAB 1 - ƒê·ªÅ xu·∫•t
    with tab1:
        st.header("üîç Motorcycle H·ªá th·ªëng ƒë·ªÅ xu·∫•t")
        rec_mode = st.radio("Ch·ªçn c√°ch g·ª£i √Ω:", ["Theo danh m·ª•c c√≥ s·∫µn", "Theo t·ª´ kh√≥a"])

        if rec_mode == "Theo danh m·ª•c c√≥ s·∫µn":  
            st.subheader("üîç T√¨m ki·∫øm theo danh m·ª•c xe")

            # Nh·∫≠p t·ª´ kh√≥a
            keyword = st.text_input("Nh·∫≠p t·ª´ kh√≥a ƒë·ªÉ l·ªçc danh m·ª•c:")

            # T·∫°o danh s√°ch g·ª£i √Ω danh m·ª•c
            if keyword.strip() == "":
                # 10 danh m·ª•c ng·∫´u nhi√™n
                suggested_titles = df["Ti√™u ƒë·ªÅ"].sample(10, random_state=42).tolist()
            else:
                # L·ªçc theo keyword (kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng)
                suggested_titles = df[df["Ti√™u ƒë·ªÅ"].str.contains(keyword, case=False, na=False)] \
                                    ["Ti√™u ƒë·ªÅ"].head(10).tolist()

                if len(suggested_titles) == 0:
                    st.warning("‚ùó Kh√¥ng t√¨m th·∫•y danh m·ª•c ph√π h·ª£p. Hi·ªÉn th·ªã danh m·ª•c ng·∫´u nhi√™n.")
                    suggested_titles = df["Ti√™u ƒë·ªÅ"].sample(10, random_state=42).tolist()

            # Ch·ªçn ti√™u ƒë·ªÅ
            selected_title = st.selectbox("Ch·ªçn danh m·ª•c xe c·∫ßn t√¨m g·ª£i √Ω:", suggested_titles)

            # S·ªë l∆∞·ª£ng g·ª£i √Ω
            nums = st.slider("S·ªë l∆∞·ª£ng g·ª£i √Ω:", 3, 20, 7)

            # L·∫•y ID t·ª´ ti√™u ƒë·ªÅ ƒë√£ ch·ªçn
            selected_id = int(df[df["Ti√™u ƒë·ªÅ"] == selected_title]["id"].values[0])

            if st.button("üîé G·ª£i √Ω theo danh m·ª•c"):
                result = get_recomendations(selected_id, nums=nums)
                st.markdown("""
                **üîπ Cosine Similarity** 
                - Gi√° tr·ªã t·ª´ **0 ‚Üí 1**. C√†ng g·∫ßn **1** ‚Üí Hai m√¥ t·∫£ xe c√†ng gi·ªëng nhau.  
                - **> 0.7** ‚Üí T∆∞∆°ng ƒë·ªìng m·∫°nh (r·∫•t li√™n quan).  
                - 0.4 ‚Äì 0.7 ‚Üí T∆∞∆°ng ƒë·ªìng trung b√¨nh.  
                - **< 0.3** ‚Üí T∆∞∆°ng ƒë·ªìng th·∫•p.
                """)                 
                st.dataframe(result)

                # WordCloud t·ª´ c√°c ti√™u ƒë·ªÅ g·ª£i √Ω
                text = " ".join(result["Ti√™u ƒë·ªÅ"].astype(str))
                wc = WordCloud(width=800, height=350, background_color="white").generate(text)
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.imshow(wc, interpolation="bilinear")
                ax.axis("off")
                st.pyplot(fig)               

        if rec_mode == "Theo t·ª´ kh√≥a":
            keyword = st.text_input("Nh·∫≠p t·ª´ kh√≥a:")
            nums = st.slider("S·ªë l∆∞·ª£ng g·ª£i √Ω:", 3, 20, 7)

            if st.button("üîé G·ª£i √Ω theo t·ª´ kh√≥a"):
                result = recommend_by_keyword(keyword, nums)
                st.markdown("""
                **üîπ Cosine Similarity** 
                - Gi√° tr·ªã t·ª´ **0 ‚Üí 1**. C√†ng g·∫ßn **1** ‚Üí Hai m√¥ t·∫£ xe c√†ng gi·ªëng nhau.  
                - **> 0.7** ‚Üí T∆∞∆°ng ƒë·ªìng m·∫°nh (r·∫•t li√™n quan).  
                - 0.4 ‚Äì 0.7 ‚Üí T∆∞∆°ng ƒë·ªìng trung b√¨nh.  
                - **< 0.3** ‚Üí T∆∞∆°ng ƒë·ªìng th·∫•p.
                """)                
                st.dataframe(result)

                text = " ".join(result["Ti√™u ƒë·ªÅ"].astype(str))
                wc = WordCloud(width=800, height=350, background_color="white").generate(text)
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.imshow(wc, interpolation="bilinear")
                ax.axis("off")
                st.pyplot(fig)

    # ---------------- INIT SESSION STATE ----------------
    defaults = {
        "cluster_model": None,
        "labels": None,
        "encoder": None,
        "scaler": None,
        "df2_cluster": None,
        "X2_scaled": None,
        "cluster_summary": None,
        "cluster_labels": {},
        "survey_done": False,
        "inertia": None,
        "sil_scores": None
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

    # ---------------- BUILD CLUSTER DATASET ----------------
    def build_cluster_dataset(df):
        """Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ ph√¢n c·ª•m v·ªõi PowerTransformer"""
        features = ['Gi√°_num', 'Km_num', 'Dung_tich_num', 'NƒÉm ƒëƒÉng k√Ω', 'Th∆∞∆°ng hi·ªáu']
        df2 = df[features].dropna()

        encoder = CatBoostEncoder()
        brand_encoded = encoder.fit_transform(df2['Th∆∞∆°ng hi·ªáu'], df2['Gi√°_num'])

        scaler = PowerTransformer(method="yeo-johnson", standardize=True)
        numeric_scaled = scaler.fit_transform(
            df2[['Gi√°_num', 'Km_num', 'Dung_tich_num', 'NƒÉm ƒëƒÉng k√Ω']]
        )

        X = np.concatenate([numeric_scaled, brand_encoded.values], axis=1)
        return X, df2, encoder, scaler

    # ---------------- TAB 2: Ph√¢n c·ª•m ----------------
    with tab2:
        st.header("üì¶ Ph√¢n c·ª•m xe m√°y")

        # Build dataset
        X2_scaled, df2_cluster, encoder, scaler = build_cluster_dataset(df)

        # ==============================================
        #   TR∆Ø·ªúNG H·ª¢P ADMIN ‚Äî ƒê·∫¶Y ƒê·ª¶ CH·ª®C NƒÇNG
        # ==============================================
        if st.session_state.app_mode == "admin":

            # ====== KH·∫¢O S√ÅT S·ªê C·ª§M ======
            if st.button("üîç Kh·∫£o s√°t s·ªë c·ª•m"):
                K_range = range(2, 10)
                inertia = []
                sil_scores = []

                st.session_state.survey_done = False

                for k_tmp in K_range:
                    kmeans_tmp = KMeans(n_clusters=k_tmp, random_state=42)
                    labels_tmp = kmeans_tmp.fit_predict(X2_scaled)
                    inertia.append(kmeans_tmp.inertia_)
                    sil_scores.append(silhouette_score(X2_scaled, labels_tmp))

                st.session_state.survey_done = True
                st.session_state.inertia = inertia
                st.session_state.sil_scores = sil_scores
                st.success("ƒê√£ ho√†n th√†nh kh·∫£o s√°t s·ªë c·ª•m!")

            if st.session_state.get("survey_done", False):
                K_range = range(2, 10)

                fig_elbow, ax_elbow = plt.subplots()
                ax_elbow.plot(K_range, st.session_state.inertia, "o-")
                ax_elbow.set_xlabel("S·ªë c·ª•m (k)")
                ax_elbow.set_ylabel("Inertia")
                ax_elbow.set_title("Bi·ªÉu ƒë·ªì Elbow")
                st.pyplot(fig_elbow)

                fig_sil, ax_sil = plt.subplots()
                ax_sil.plot(K_range, st.session_state.sil_scores, "o-")
                ax_sil.set_xlabel("S·ªë c·ª•m (k)")
                ax_sil.set_ylabel("Silhouette Score")
                ax_sil.set_title("Bi·ªÉu ƒë·ªì Silhouette")
                st.pyplot(fig_sil)

            # ===== CH·ªåN THU·∫¨T TO√ÅN, CH·∫†Y PH√ÇN C·ª§M =====
            k = st.number_input("üî¢ Ch·ªçn s·ªë c·ª•m t·ªëi ∆∞u", min_value=2, max_value=15, value=4, step=1)
            algo = st.selectbox(
                "Ch·ªçn thu·∫≠t to√°n ph√¢n c·ª•m",
                ["KMeans", "Gaussian Mixture", "Agglomerative"]
            )

            if st.button("üöÄ Ch·∫°y ph√¢n c·ª•m"):
                if algo == "KMeans":
                    model = KMeans(n_clusters=k, random_state=42)
                    labels = model.fit_predict(X2_scaled)
                elif algo == "Gaussian Mixture":
                    model = GaussianMixture(n_components=k, random_state=42)
                    labels = model.fit_predict(X2_scaled)
                else:
                    model = AgglomerativeClustering(n_clusters=k)
                    labels = model.fit_predict(X2_scaled)

                sil = silhouette_score(X2_scaled, labels)

                st.session_state.cluster_model = model
                st.session_state.labels = labels
                st.session_state.X2_scaled = X2_scaled
                st.session_state.encoder = encoder
                st.session_state.scaler = scaler

                df2_cluster['Cluster'] = labels
                st.session_state.df2_cluster = df2_cluster.copy()

                st.session_state.cluster_labels = {}
                st.session_state.total_items = len(df2_cluster)
                st.session_state.total_clusters = k

                st.success(f"üéØ ƒê√£ ph√¢n c·ª•m th√†nh c√¥ng b·∫±ng {algo} ‚Äî Silhouette = {sil:.3f}")
                st.markdown("""
                **üîπ Silhouette Score**
                - ƒê√°nh gi√° **m·ª©c ƒë·ªô t√°ch bi·ªát gi·ªØa c√°c c·ª•m** v√† **m·ª©c ƒë·ªô t·∫≠p trung trong t·ª´ng c·ª•m**. Gi√° tr·ªã n·∫±m trong kho·∫£ng **[-1, 1]**.  
                - C√†ng g·∫ßn **1** ‚Üí C·ª•m ph√¢n chia c√†ng r√µ r√†ng, d·ªÖ t√°ch bi·ªát.  
                - T·ª´ **0.5 tr·ªü l√™n** ‚Üí Ch·∫•t l∆∞·ª£ng ph√¢n c·ª•m t·ªët.  
                - T·ª´ **0.3 ‚Äì 0.5** ‚Üí Ch·∫•p nh·∫≠n ƒë∆∞·ª£c.  
                - D∆∞·ªõi **0.25** ‚Üí C·ª•m ch·ªìng ch√©o, ch·∫•t l∆∞·ª£ng ch∆∞a t·ªët.
                """)
                # PCA visualization
                pca = PCA(n_components=2)
                comps = pca.fit_transform(X2_scaled)
                fig, ax = plt.subplots(figsize=(8, 5))
                sns.scatterplot(x=comps[:, 0], y=comps[:, 1], hue=labels, palette="tab10", ax=ax)
                st.pyplot(fig)

                # Summary
                cluster_counts = df2_cluster['Cluster'].value_counts().sort_index()
                cluster_means = df2_cluster.groupby('Cluster')[['Gi√°_num', 'Km_num', 'Dung_tich_num', 'NƒÉm ƒëƒÉng k√Ω']].mean()
                summary = pd.concat([
                    cluster_counts.rename("S·ªë l∆∞·ª£ng"),
                    cluster_means
                ], axis=1)

                st.session_state.cluster_summary = summary.copy()

            # ====== FORM ƒê·∫∂T T√äN C·ª§M ======
            if st.session_state.cluster_summary is not None:
                st.subheader("‚úèÔ∏è ƒê·∫∑t t√™n cho t·ª´ng c·ª•m")

                with st.form("form_cluster_name"):
                    new_labels = {}
                    for cid in st.session_state.cluster_summary.index:
                        default = st.session_state.cluster_labels.get(cid, f"C·ª•m {cid}")
                        new_labels[cid] = st.text_input(f"T√™n c·ª•m {cid}", value=default)
                    submitted = st.form_submit_button("üíæ L∆∞u t√™n c·ª•m")

                if submitted:
                    st.session_state.cluster_labels = new_labels
                    updated = st.session_state.cluster_summary.copy()
                    updated["T√™n c·ª•m"] = [new_labels[c] for c in updated.index]
                    cols = ["T√™n c·ª•m"] + [c for c in updated.columns if c != "T√™n c·ª•m"]
                    updated = updated[cols]
                    st.session_state.cluster_summary = updated
                    st.success("‚úî ƒê√£ c·∫≠p nh·∫≠t t√™n c·ª•m!")

        # ==============================================
        #     TR∆Ø·ªúNG H·ª¢P NG∆Ø·ªúI D√ôNG ‚Äî CH·ªà ƒê∆Ø·ª¢C XEM
        # ==============================================
        else:
            st.info("üë§ B·∫°n ƒëang ·ªü ch·∫ø ƒë·ªô Ng∆∞·ªùi d√πng ‚Äî ch·ªâ ƒë∆∞·ª£c xem k·∫øt qu·∫£ ph√¢n c·ª•m ƒë√£ ƒë∆∞·ª£c Admin c·∫•u h√¨nh.")

        # ===== HI·ªÇN TH·ªä B·∫¢NG TH·ªêNG K√ä (D√ô ADMIN HAY USER) =====
        if st.session_state.cluster_summary is not None:
            st.subheader("üìä B·∫£ng th·ªëng k√™ c·ª•m (ƒë√£ c·∫≠p nh·∫≠t)")
            st.dataframe(st.session_state.cluster_summary)

        # ===== D·ª∞ ƒêO√ÅN C·ª§M CHO XE M·ªöI (C·∫¢ USER & ADMIN ƒê·ªÄU X√ÄI ƒê∆Ø·ª¢C) =====
        st.subheader("üîÆ D·ª± ƒëo√°n c·ª•m cho xe m·ªõi")

        if st.session_state.cluster_model is None:
            st.warning("‚ö† B·∫°n c·∫ßn ƒë·ªÉ Admin ch·∫°y ph√¢n c·ª•m tr∆∞·ªõc!")
        else:
            gia = st.number_input("Gi√° xe", min_value=0)
            km = st.number_input("Km ƒë√£ ƒëi", min_value=0)
            cc = st.number_input("Dung t√≠ch (cc)", min_value=50)
            year = st.number_input("NƒÉm ƒëƒÉng k√Ω", min_value=1990, max_value=2025)
            brand = st.selectbox("Th∆∞∆°ng hi·ªáu", df['Th∆∞∆°ng hi·ªáu'].unique())

            if st.button("üîç Ph√¢n c·ª•m xe c·ªßa b·∫°n"):
                encoder = st.session_state.encoder
                scaler = st.session_state.scaler
                model = st.session_state.cluster_model

                new_brand = encoder.transform(pd.DataFrame({"Th∆∞∆°ng hi·ªáu": [brand]}))
                new_numeric = scaler.transform([[gia, km, cc, year]])
                X_new = np.concatenate([new_numeric, new_brand.values], axis=1)

                if hasattr(model, "predict"):
                    cluster_id = model.predict(X_new)[0]
                else:
                    centroids = np.vstack([
                        st.session_state.X2_scaled[st.session_state.labels == c].mean(axis=0)
                        for c in range(st.session_state.total_clusters or 4)
                    ])
                    cluster_id = np.argmin(np.linalg.norm(centroids - X_new, axis=1))

                cluster_label = st.session_state.cluster_labels.get(cluster_id, f"C·ª•m {cluster_id}")
                st.success(f"‚úî Xe c·ªßa b·∫°n thu·ªôc **C·ª•m {cluster_id} ‚Äì {cluster_label}!**")

# =============== PAGE: Tr·ª±c quan h√≥a =============== #
elif page == "Tr·ª±c quan h√≥a":
    require_file_loaded()

    st.subheader("üìä Tr·ª±c quan h√≥a Dashboard")

    fig1, ax1 = plt.subplots(figsize=(8, 5))
    sns.histplot(df["Gi√°"].dropna(), kde=True, ax=ax1)
    st.pyplot(fig1)

    text = " ".join(df["Ti√™u ƒë·ªÅ"].astype(str))
    wc = WordCloud(width=900, height=400, background_color="white").generate(text)
    fig2, ax2 = plt.subplots(figsize=(9, 4))
    ax2.imshow(wc, interpolation="bilinear")
    ax2.axis("off")
    st.pyplot(fig2)

    st.subheader("üìä Bi·ªÉu ƒë·ªì t·∫ßn su·∫•t th∆∞∆°ng hi·ªáu")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.countplot(data=df, x="Th∆∞∆°ng hi·ªáu", order=df["Th∆∞∆°ng hi·ªáu"].value_counts().index)
    plt.xticks(rotation=45)
    st.pyplot(fig)

# =============== PAGE: Ph·ª• tr√°ch ·ª©ng d·ª•ng =============== #
elif page == "Ph·ª• tr√°ch ·ª©ng d·ª•ng":
    st.subheader("üìã Ph·ª• tr√°ch ·ª©ng d·ª•ng")
    st.markdown("""
        ### üßë‚Äçüíª B·∫£ng ph√¢n c√¥ng c√¥ng vi·ªác
        
        | Th√†nh vi√™n           | C√¥ng vi·ªác |
        |----------------------|-----------|
        | **Nguy·ªÖn Duy Thanh** | GUI for H·ªá th·ªëng ƒë·ªÅ xu·∫•t and ph√¢n c·ª•m |
        | **Nguy·ªÖn Th√°i B√¨nh** | GUI for Price Prediction and Anomaly Detection |
    """)

#############################################################
# ===================== FOOTER ===================== #

st.sidebar.markdown("---")

avatar1_path = os.path.join(BASE_DIR, "avatar.jpg")
avatar2_path = os.path.join(BASE_DIR, "avatar_2.jpg")

avatar1 = Image.open(avatar1_path)
avatar2 = Image.open(avatar2_path)

def crop_avatar(img, offset_ratio=0.10):
    w, h = img.size
    size = min(w, h)
    offset = int(size * offset_ratio)

    left = (w - size) / 2
    top = offset
    right = (w + size) / 2
    bottom = offset + size
    bottom = min(bottom, h)

    img = img.crop((left, top, right, bottom))
    img = img.resize((80, 80), Image.LANCZOS)
    return img

avatar1 = crop_avatar(avatar1)
avatar2 = crop_avatar(avatar2)

colA, colB = st.sidebar.columns(2)
with colA:
    st.image(avatar1, width=80)
with colB:
    st.image(avatar2, width=80)

st.sidebar.markdown("""
**Designed by:**  
**Nguy·ªÖn Duy Thanh**  
Email: [duythanh200620@gmail.com](mailto:duythanh200620@gmail.com)  
**Nguy·ªÖn Th√°i B√¨nh**  
Email: [thaibinh782k1@gmail.com](mailto:thaibinh782k1@gmail.com)
""")
